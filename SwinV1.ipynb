{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SwinV1",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNpdp328XdzOl6tdNxNk1RG"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Environment Check"
      ],
      "metadata": {
        "id": "565zVejVk83L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFbxYbkQAiw6",
        "outputId": "c21d32c7-1af9-4f1d-c3fb-bb6ed91fc57d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jan 24 21:50:50 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEcvqrR6AjgQ",
        "outputId": "8bd1ee88-5d30-416e-e786-957b618cc4a8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "Not using a high-RAM runtime\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Swim V1 Transformer"
      ],
      "metadata": {
        "id": "GNgnMhr6k_0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2yCa8-RZaVN",
        "outputId": "ef6fdea2-c846-437c-be6c-68252d727938"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 8.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches"
      ],
      "metadata": {
        "id": "2Cyg4T9Pk6CZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention Block"
      ],
      "metadata": {
        "id": "-_n_Lg6pBcrJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(layers.Layer):\n",
        "    def __init__(self, numpatchesdim=7, querykeydim=32):\n",
        "        super(Attention, self).__init__()\n",
        "        self.M2 = numpatchesdim*numpatchesdim\n",
        "        self.d = querykeydim\n",
        "        self.K = self.add_weight(\n",
        "            shape=(self.M2, self.d), initializer=\"random_normal\", trainable=True\n",
        "        )\n",
        "        self.V = self.add_weight(\n",
        "            shape=(self.M2, self.d), initializer=\"random_normal\", trainable=True\n",
        "        )\n",
        "        self.B = self.add_weight(\n",
        "            shape=(self.M2, self.M2), initializer=\"random_normal\", trainable=True\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        Q = inputs\n",
        "        attn = Q @ tf.transpose(self.K) / tf.math.sqrt(tf.cast(self.d, tf.float32))\n",
        "        attn = tf.nn.softmax(attn) @ self.V\n",
        "        return attn\n"
      ],
      "metadata": {
        "id": "My9_nh88BdnF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attention Block Testing"
      ],
      "metadata": {
        "id": "mDehyQTXErOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numpatchesdim = 7\n",
        "querykeydim = 32\n",
        "attnlayer = Attention(numpatchesdim=numpatchesdim,\n",
        "                      querykeydim=querykeydim)\n",
        "Q = tf.ones(shape=(numpatchesdim*numpatchesdim, querykeydim))\n",
        "out = attnlayer(Q)"
      ],
      "metadata": {
        "id": "RMJ7WjEeEXNM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aANXl--iFOGc",
        "outputId": "fc694ea4-c180-4984-f8e6-61d6af0d1d48"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(49, 32), dtype=float32, numpy=\n",
              "array([[-0.00201054,  0.00519757, -0.00151976, ..., -0.00219627,\n",
              "        -0.00044917,  0.00808715],\n",
              "       [-0.00201054,  0.00519757, -0.00151976, ..., -0.00219627,\n",
              "        -0.00044917,  0.00808715],\n",
              "       [-0.00201054,  0.00519757, -0.00151976, ..., -0.00219627,\n",
              "        -0.00044917,  0.00808715],\n",
              "       ...,\n",
              "       [-0.00201054,  0.00519757, -0.00151976, ..., -0.00219627,\n",
              "        -0.00044917,  0.00808715],\n",
              "       [-0.00201054,  0.00519757, -0.00151976, ..., -0.00219627,\n",
              "        -0.00044917,  0.00808715],\n",
              "       [-0.00201054,  0.00519757, -0.00151976, ..., -0.00219627,\n",
              "        -0.00044917,  0.00808715]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hBPwVnFFGFU0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}